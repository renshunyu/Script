./kafka-run-class.sh kafka.tools.ConsumerOffsetChecker --group aus-group --zookeeper 10.1.198.61:5181/consumers

select hour(operate_time),count(1) from iap_app_log_import_minute t where day(operate_time)=16 and t.import_time like '2016-12-%' group by hour(operate_time) order by hour(operate_time)

github.com/datafoundry/training


https://github.com/boot2docker/windows-installer/releases/download/v1.8.0/docker-install.exe



https://s10d.storage.yandex.net/rdisk/298936885f85c44263ceeb8d5115061b1a57905840d11317b1e18beff9866d64/586f837d/jEureRSpFNh_apPkYXRiEbDkDPeu5Pequ1x2x7rAss1ytX5wlJUVngyKFVaEkdmzxtMjoq7FCj7rT2EIZwHWMQ==?uid=0&filename=Chromedriver.zip&disposition=attachment&hash=3CuUzVwzoPngn5ni7J8Py1FXq7xEJUoA4qLJo85CyiM%3D%3A&limit=1&content_type=application%2Fx-zip-compressed&fsize=2398137&hid=fa0499d064d79ae880ea0ba05a7d64a1&media_type=compressed&tknv=v2&rtoken=xDKrCi7gkOY6&force_default=no&ycrid=na-e43e9baa155c213653a37c4a9daba488-downloader8g&ts=5456b901a1940&s=e4655db1d8de60e4ecf76cdc047dd38ee02243ce95ec0efd5de43c5c542eafd7&bp=/45/7/data-0.9:17485928220:2398137&pb=U2FsdGVkX1-UYrQTfKWyblzWoXfBWG1R65sdXI2SSMGTT2Hdzndgf4Tteb2Lm9z2g8oNWnXB8-pm-tdhSGE1CkEbc2GtGQgl9ggs90hMrdU=


bin/kafka-console-consumer.sh --zookeeper 10.1.198.61:5181 --topic tcp-xml --from-beginning


sh kafka-console-consumer.sh --zookeeper 10.1.198.61:5181 --topic tcp-xml --from-beginning|grep 1-SIMS-1-10008|grep 2016-12


/ai4a30/aisia1.0/产品发布/aisiav04r00c00_20161111/安装包/iap.war


java -jar "selenium-server-standalone-2.52.0.jar" -Dwebdriver.chrome.bin=".\chromedrivesr.exe"

ClassPathXmlApplicationContext actx=new ClassPathXmlApplicationContext("main-spring.xml");
File fi = (File) actx.getBean("filepath");


imp audit30testa/audit30testa#@iap file=oridev_cmdlog_201701.dmp full=y log=1.log

pip install http://wxpython.org/Phoenix/snapshot-builds/ wxPython_Phoenix

./zookeeper-server-cleanup /var/lib/zookeeper/version-2  2

src/main/resource

sudo chgrp -R zookeeper /app/lib/zookeeper
sudo chown -R zookeeper /app/lib/zookeeper

cat xml.out |grep LOG4A|awk -F '[<>]' '{a[$47]++}END{for (i in a) {print $i}}'
cat xml.out |grep LOG4A|awk -F '[<>]' '{print $47}'
cat xml.out |grep LOG4A|awk -F '[<>]' '{j=NR;print $0 >> j".xml"}'
cat ../xml.out |grep LOG4A|awk -F '[<>]' '{print $0 >> $27".txt"}'
rm $(ls |grep 20072|awk '{if (NR!=1){print $1}}')
cat xml.out |grep LOG4A|awk -F '[<>]' '{a[$27]++}END{for (i in a) {print i"  "a[i]}}'
cat xml.out |grep LOG4A|awk -F '[<>]' '{a[$47]++}END{for (i in a) {print i"  "a[i]}}'




kill -9 $(ps -ef |grep GatherSend|grep -v grep|awk '{print $2}')
sh /home/aiuap/autobuild/gather_serverbuild.sh 
sh /home/aiuap/autobuild/gather_server_tcp-xml_deploy.sh
sleep 5
sh start.sh uac record 30
tail -f /home/aiuap30/gather30/ap_gather_server_tcp-xml/ap_gather_server_tcp-xml/log/ap.log


kill -9 $(ps -ef |grep ap_gather_server_tcp-xml|grep -v grep|awk '{print $2}')
csh start ap_gather_server_tcp-xml


curl -XGET 10.19.19.40:8990/_cluster/health -u kibanaserver:Kibanaserver4A@2017




cat * |grep UAP|awk -F 'SUB_ACCOUNT_NAME' '{print $2}'|sed 's/>//g'|sed 's/<\///g'
cat * |grep UAP|awk -F 'SERVER_ADDRESS' '{print $2}'|sed 's/>//g'|sed 's/<\///g'
cat * |grep UAP|awk -F 'OPERATE_RESULT' '{print $2}'|sed 's/>//g'|sed 's/<\///g'
cat * |grep UAP|awk -F 'OP_TYPE_ID' '{print $2}'|sed 's/>//g'|sed 's/<\///g'
cat * |grep UAP|awk -F 'RESOURCE_CODE' '{print $2}'|sed 's/>//g'|sed 's/<\///g'
cat * |grep UAP|awk -F 'MAIN_ACCOUNT_NAME' '{print $2}'|sed 's/>//g'|sed 's/<\///g'
cat * |grep UAP|awk -F 'SERVER_PORT' '{print $2}'|sed 's/>//g'|sed 's/<\///g'
cat * |grep UAP|awk -F 'CLIENT_NETWORK_ADDRESS' '{print $2}'|sed 's/>//g'|sed 's/<\///g'
cat * |grep UAP|awk -F 'OPERATE_TIME' '{print $2}'|sed 's/>//g'|sed 's/<\///g'
cat * |grep UAP|awk -F 'OPERATE_CONTENT' '{print $2}'|sed 's/>//g'|sed 's/<\///g'


find audittest |grep no |awk '{print "csh logsendtool.sh uac "$1}'
keyihelvmengduijie
xitongziyuanjiangkong
zhichiweixin
rizhi  shiijanzhuangfa


export JAVA_HOME=/usr/java/jdk1.8.0_121
export CLASSPATH=$(echo $CLASSPATH|sed 's/jdk1.6.0_31/jdk1.8.0_121/g')
export PATH=$(echo $PATH:$HOME/bin:/home/aiuap/tools/apache-ant-1.7.1/bin|sed 's/jdk1.6.0_31/jdk1.8.0_121/g')


<CLIENT_BOIS_SERIAL>1234567890</CLIENT_BOIS_SERIAL><HARD_DISK_SERIAL>0987654321</HARD_DISK_SERIAL>
sed -i "s/<ROOT><LOG4A>/<ROOT><LOG4A><CLIENT_BOIS_SERIAL>1234567890<\/CLIENT_BOIS_SERIAL><HARD_DISK_SERIAL>0987654321<\/HARD_DISK_SERIAL>/g"  主帐号*

vi /etc/security/limits.d/90-nproc.conf 
修改如下内容：
* soft nproc 1024
#修改为
* soft nproc 10240


alter database add logfile group 4 ('/aifs01/oracle11g/oradata/iap/redo04.log') size 1024M;
alter database add logfile group 5 ('/aifs01/oracle11g/oradata/iap/redo05.log') size 1024M;
alter database add logfile group 6 ('/aifs01/oracle11g/oradata/iap/redo06.log') size 1024M;

echo 'select count(*) from v$process'|sqlplus audit30testa/audit30testa#@ai4a

echo 'select count(*) from v$process;'|sqlplus audit30testa/audit30testa#@iap |grep '    '|awk '{print $NF}'

mvn install:install-file -Dfile=ap-simulator-1.0.jar -DgroupId=com.asiainfo -DartifactId=ap-simulator -Dversion=1.0 -Dpackaging=jar
mvn install:install-file -Dfile=ap-commons-1.0.jar -DgroupId=com.asiainfo -DartifactId=ap-commons -Dversion=1.0 -Dpackaging=jar
mvn install:install-file -Dfile=ojdbc6-11.2.0.3.jar -DgroupId=com.oracle -DartifactId=ojdbc6 -Dversion=11.2.0.3 -Dpackaging=jar

cat `ls -t|grep err.log|awk 'NR<3'`|grep "`date '+%F %H:%M' -d '2017-07-22 14:20:02,180'`"

ls -t|grep err.log|awk 'NR<3'

sed "s\value=\".*?\"\value=\"`date "+%S %M %H * * ?" -d '60 second'`\"\g" iap-spring-report.xml 
sed "30 s/value=\".*\"/value=\"`date "+%S %M %H * * ?" -d '60 second'`\"/g" iap-spring-report.xml
sqlplus audit30testa/audit30testa#@10.15.42.37:1521/iap


echo 'truncate table MODEL_MIDDLE_DETAIL_RESULT;'|sqlplus audit30testa/audit30testa#@10.15.42.37:1521/iap
echo "truncate table MODEL_MIDDLE_DETAIL_RESULT;
update iap_report_schedule set his_data_analysis_finish_time='' where report_id = 'ModelAudit ';
commit;"|sqlplus audit30testa/audit30testa#@10.15.42.37:1521/iap
echo 'use aiiap;
truncate table MODEL_MIDDLE_DETAIL_RESULT;' |hive

echo 'use aiiap;
show partitions MODEL_MIDDLE_DETAIL_RESULT;' |hive|grep operate_day|awk -F= '{print "use aiiap;\nalter table MODEL_MIDDLE_DETAIL_RESULT drop partition("$1"='\''"$2"'\'');" }'|hive

Insert into IAP_APP_LOG_ANALUSE_NORMAL_RESULT select  '10000048',t.main_acct_name ,'1-AIUAP-80005',t.operate_type_name,'70' from  aiiaptestc.iap_app_log_operate_day t where t.main_acct_id = '10000048' and t.operate_type_id = '1-AIUAP-80005' and  t.operate_day='2017-08-02' limit 1;
Insert into IAP_APP_LOG_ANALUSE_NORMAL_RESULT select  '10000038',t.main_acct_name ,'1-AIUAP-20427',t.operate_type_name,'70' from  aiiaptestc.iap_app_log_operate_day t where t.main_acct_id = '10000038' and t.operate_type_id = '1-AIUAP-20427' and  t.operate_day='2017-07-19' limit 1;
Insert into IAP_APP_LOG_ANALUSE_NORMAL_RESULT select t.main_acct_id,t.main_acct_name,t.operate_type_id,t.operate_type_name,'70' as num from  aiiaptestc.iap_app_log_operate_day t where t.operate_day = '2017-07-20' and t.main_acct_name<>'NULL' and t.operate_type_name not in ('主帐号加锁','主帐号新建','主帐号解锁') group by t.main_acct_id,t.main_acct_name,t.operate_type_id,t.operate_type_name;

select * from  iap_app_log_operate_day t where t.main_acct_id = '10000048' and t.operate_type_id = '1-AIUAP-80005' and  t.operate_day='2017-08-02';
select * from  iap_app_log_operate_day t where t.main_acct_id = '10000038' and t.operate_type_id = '1-AIUAP-20427' and  t.operate_day='2017-07-20';

pwdx `jps|grep ReportApp|awk '{print $1}'`
sudo netstat -anop |grep 1521|awk '{a[$7]++}END{for(i in a){print i" "a[i]}}'
hadoop fs -du -h `hadoop fs -du -h /user/hive/warehouse/aiiap.db/iap_app_log_operate_day/|grep 2017-07|awk '{print $5}'`|grep K|awk '{print $NF}'|awk -F/ '{a[$7]++}END{for(i in a){print i" "a[i]}}'
grep -n ERROR catalina.out |awk -F: '{a[$2]++}END{for( i in a ){print i" "a[i]}}'|sort

curl -XGET -u kibanaserver:Kibanaserver4A@2017 http://10.1.198.55:8990/app-log-v1/_count
hadoop fs -ls /user/hive/warehouse/aiiap.db/iap_app_log_operate_day|grep =|awk -F/ '{print "use aiiap;\nalter table iap_app_log_operate_day add partition("$NF"'\'');"}'|sed "s/=/='/g"|hive
hadoop fs -lsr  /user/hive/warehouse/aiiaptestc.db/|grep =|awk -F/ '{print "alter table "$6" add partition("$NF"'\'');"}'|sed "s/=/='/g"|grep =
hadoop fs -lsr  /user/hive/warehouse/aiiaptestc.db/|grep =|awk -F= '(NF>1 && !match($NF,"/")){print $0}'|awk -F/ '{if(NF==7){print "alter table "$6" add partition("$7"'\'');"};if(NF==8){print "alter table "$6" add partition("$7"'\'',"$8"'\'');"}}'|sed "s/=/='/g"
hadoop fs -lsr  /user/hive/warehouse/aiiaptestc.db/|grep =|awk -F= '(NF>1 && !match($NF,"/")){print $0}'|awk -F/ '{if(NF==7){print "use aiiaptestc;\nalter table "$6" add partition("$7"'\'');"};if(NF==8){print "use aiiaptestc;\nalter table "$6" add partition("$7"'\'',"$8"'\'');"}}'|sed "s/=/='/g"|hive

for i in $(ls /proc | grep "^[0-9]" | awk '$0>100'); do awk '/Swap:/{a=a+$2}END{print '"$i"',a/1024"M"}' /proc/$i/smaps;done| sort -k2nr | head -n 20|awk '{print $1}'|xargs pwdx

SELECT TO_CHAR(TO_DATE('2009-04' || '-1', 'YYYY-MM-DD') + ROWNUM - 1,
               'YYYYMMDD') D1,TO_CHAR(TO_DATE('2009-04' || '-1', 'YYYY-MM-DD') + ROWNUM,
               'YYYY-MM-DD hh24:mi:ss') D2
  FROM DUAL
CONNECT BY ROWNUM <=32 

SELECT 'partition IAP_ORI_'||TO_CHAR(TO_DATE('2017-12' || '-1', 'YYYY-MM-DD') + ROWNUM - 1,
               'YYYYMMDD')||' values less than (TIMESTAMP'''||TO_CHAR(TO_DATE('2017-12' || '-1', 'YYYY-MM-DD') + ROWNUM,
               'YYYY-MM-DD hh24:mi:ss')||'''),'
  FROM DUAL
CONNECT BY ROWNUM <=32 ;

SELECT TO_CHAR(ADD_MONTHS(TO_DATE('2009-03', 'YYYY-MM'), ROWNUM - 1),
               'YYYY-MM') DAY_ID
  FROM DUAL
CONNECT BY ROWNUM <=
           months_between(to_date('2010-03', 'yyyy-mm'),
                          to_date('2009-03', 'yyyy-mm')) + 1


echo 'use aiiaptestc;
show partitions iap_app_log_import_minute;'|hive |grep 2017-09|awk -F = '{print "use aiiaptestc;\nalter table iap_app_log_import_minute drop partition ("$1"='\''"$2"'\'');"}'|hive

#oracle延迟函数
select dbms_pipe.receive_message('RDS', 10)   from dual;

project = SSSIA AND issuetype = 故障 AND assignee in (lusm, wangsz, tanrq, yutong3, zhangjy11, rensy, zhanghl8, liufd)
project = SSSIA AND issuetype = 故障 AND status in (Open, 已上线, 已发布, 待发布, 待测试, 测试中, 定位中, 待修复, 故障修复中, 已提交) AND assignee not in (lusm, wangsz, tanrq, yutong3, zhangjy11, rensy, zhanghl8, liufd)

for i in 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29; 

do 

echo $i;

sudo dd if=/dev/zero of=/usr/swap_file$i bs=2G count=1;

sudo chmod 600 /usr/swap_file$i;

sudo mkswap /usr/swap_file$i;

sudo swapon /usr/swap_file$i;

#/usr/swap_file10 swap swap defaults 0 0

done

select decode(data_type,
              'TIMESTAMP(6)',
              'to_char(' || t.COLUMN_NAME ||
              ',''yyyy-mm-dd hh24:mi:ss'') as ' || t.COLUMN_NAME || ',',
              'DATE',
              'to_char(' || t.COLUMN_NAME ||
              ',''yyyy-mm-dd hh24:mi:ss'') as ' || t.COLUMN_NAME || ',',
              t.COLUMN_NAME||',') as COLUMN_NAME
  from user_tab_columns t
 where t.TABLE_NAME = 'UAP_MAIN_ACCT';

select 'select '||wm_concat(COLUMN_NAME) || ' from ' || 'UAP_MAIN_ACCT'
  from (select decode(data_type,
                      'TIMESTAMP(6)',
                      'to_char(' || t.COLUMN_NAME ||
                      ',''yyyy-mm-dd hh24:mi:ss'') as ' || t.COLUMN_NAME,
                      'DATE',
                      'to_char(' || t.COLUMN_NAME ||
                      ',''yyyy-mm-dd hh24:mi:ss'') as ' || t.COLUMN_NAME,
                      t.COLUMN_NAME) as COLUMN_NAME
          from user_tab_columns t
         where t.TABLE_NAME = 'UAP_MAIN_ACCT');

select (select 'select ' || wm_concat(decode(data_type,
                                             'TIMESTAMP(6)',
                                             'to_char(' || t.COLUMN_NAME ||
                                             ',''yyyy-mm-dd hh24:mi:ss'') as ' ||
                                             t.COLUMN_NAME,
                                             'DATE',
                                             'to_char(' || t.COLUMN_NAME ||
                                             ',''yyyy-mm-dd hh24:mi:ss'') as ' ||
                                             t.COLUMN_NAME,
                                             t.COLUMN_NAME)) || ' from ' ||
               ut.table_name
          from user_tab_columns t
         where t.TABLE_NAME = ut.table_name)
  from user_tables ut;

 watch -n 5 " echo 'use iaptest;

select count(1) from IAP_ORI_APP_LOG_201705;'|mysql -u root -p'2wsx#EDC'"


awk '$1=="INSERT" || $1=="insert"{print $3}' 07_全部表数据.sql 



svn cp -m "create branch" http://10.1.198.30/svn/UAPPROGRAM/products/ailkiap30/program/iap http://10.1.198.30/svn/UAPPROGRAM/products/ailkiap30/release/aisiav04r04c02_20180509/iap
PJ=data-reporting&&svn cp -m "create branch" http://10.1.198.30/svn/UAPPROGRAM/products/ailkiap30/program/$PJ http://10.1.198.30/svn/UAPPROGRAM/products/ailkiap30/release/aisiav04r04c02_20180509/$PJ
svn -r133313:134535 log http://10.1.198.30/svn/UAPPROGRAM/products/ailkiap30/program/iap
svn diff -r134866:134581 --summarize http://10.1.198.30/svn/UAPPROGRAM/products/ailkiap30
svn log http://10.1.198.30/svn/UAPPROGRAM/products/ailkiap30/release/aisiav04r20c00-pacth03_20171128/iap --stop-on-copy -q
java -jar hudson-cli.jar -s http://10.1.198.53:9080/hudson build iap -p sadf=ewdwq

ncftpput -u 'ai\rensy' -p '3edc@WSX' -P 21 -m -R 10.1.252.239 ./ai4a30/aisia1.0/临时开发版/ 

svn info `ls |grep -v 'iap_aus_zjy'` |grep 'URL:'